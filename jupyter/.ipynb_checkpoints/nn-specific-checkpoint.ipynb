{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Mean: 0.232\n",
      "Progress: 1000 of 17438\n",
      "Progress: 2000 of 17438\n",
      "Progress: 3000 of 17438\n",
      "Progress: 4000 of 17438\n",
      "Progress: 5000 of 17438\n",
      "Progress: 6000 of 17438\n",
      "Progress: 7000 of 17438\n",
      "Progress: 8000 of 17438\n",
      "Progress: 9000 of 17438\n",
      "Progress: 10000 of 17438\n",
      "Progress: 11000 of 17438\n",
      "Progress: 12000 of 17438\n",
      "Progress: 13000 of 17438\n",
      "Progress: 14000 of 17438\n",
      "Progress: 15000 of 17438\n",
      "Progress: 16000 of 17438\n",
      "Progress: 17000 of 17438\n",
      "Written training data to /home/berscheid/Documents/data/cylinder-1/gen-specific/train.csv\n",
      "Written test data to /home/berscheid/Documents/data/cylinder-1/gen-specific/test.csv\n"
     ]
    }
   ],
   "source": [
    "from generate_input_planar_pose_specific import GenerateInputPlanarPoseSpecific\n",
    "\n",
    "directory = os.path.expanduser('~/Documents/data/')\n",
    "\n",
    "generator = GenerateInputPlanarPoseSpecific([\n",
    "    directory + 'cylinder-1/cylinder-1b.db',\n",
    "    directory + 'cube-1/cube-1.db',\n",
    "], output_folder='gen-specific/')\n",
    "\n",
    "generator.generateInput({\n",
    "    'did_grasp_weight': 0.13,  # empiric value, false positive vs. false negative error\n",
    "    'force_rewrite': False,\n",
    "    'n_pos_pos': 24,\n",
    "    'n_pos_neg': 12,\n",
    "    'n_pos_no_ann': 10,\n",
    "    'n_neg_neg': 10,\n",
    "    'n_neg_no_ann': 2,\n",
    "    'size_cropped': (200, 200),\n",
    "    'size_input': (752, 480),\n",
    "    'size_output': (32, 32),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 3522\n",
      "Reward Mean: 0.23083475298126066\n",
      "Length: 13916\n",
      "Reward Mean: 0.23253808565679793\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_specific_loader import DataLoader\n",
    "\n",
    "# N: 24, 12, 10, 10, 2\n",
    "test_loader = DataLoader(generator.test_output_filename, n_pos_pos=12, n_pos_neg=4, n_neg_neg=3, n_pos_no_ann=3, n_neg_no_ann=3, label_fields=['reward', 'gripper_class', 'weights'])\n",
    "train_loader = DataLoader(generator.train_output_filename, n_pos_pos=12, n_pos_neg=4, n_neg_neg=3, n_pos_no_ann=3, n_neg_no_ann=3, label_fields=['reward', 'gripper_class', 'weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_utils import single_class_split, tf_accuracy, tf_precision, tf_recall, tf_f1\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# tf.set_random_seed(3)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(train_loader.nextBatch, (tf.float32, tf.float32, tf.float32), ((None, None, None, 1), (None, None, None, 1), (None, 3)))\n",
    "test_dataset = tf.data.Dataset.from_generator(test_loader.entireBatch, (tf.float32, tf.float32, tf.float32))\n",
    "\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=(), name='handle')\n",
    "iterator = tf.data.Iterator.from_string_handle(handle, train_dataset.output_types, train_dataset.output_shapes)\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "\n",
    "image, ann, label = iterator.get_next()\n",
    "\n",
    "\n",
    "def leaky_relu(x): return tf.nn.leaky_relu(x, 0.05)\n",
    "def reg(l1 = 0.0, l2 = 0.2):return tf.contrib.layers.l1_l2_regularizer(l1, l2)\n",
    "\n",
    "\n",
    "training = tf.placeholder_with_default(False, (), name='training')\n",
    "image = tf.identity(image, name='image')\n",
    "ann = tf.identity(ann, name='ann')\n",
    "\n",
    "x = tf.concat([image, ann], 3)\n",
    "\n",
    "x = tf.layers.conv2d(x, 32, (3, 3), strides=(2, 2), activation=leaky_relu, kernel_regularizer=reg(), bias_regularizer=reg())\n",
    "x = tf.layers.batch_normalization(x, training=training)\n",
    "    \n",
    "x = tf.layers.conv2d(x, 48, (5, 5),  activation=leaky_relu, kernel_regularizer=reg(), bias_regularizer=reg())\n",
    "x = tf.layers.batch_normalization(x, training=training)\n",
    "x = tf.layers.dropout(x, rate=0.5, training=training)\n",
    "\n",
    "x = tf.layers.conv2d(x, 64, (5, 5), activation=leaky_relu, kernel_regularizer=reg(), bias_regularizer=reg())\n",
    "x = tf.layers.batch_normalization(x, training=training)\n",
    "x = tf.layers.dropout(x, rate=0.4, training=training)\n",
    "\n",
    "x = tf.layers.conv2d(x, 128, (6, 6),  activation=leaky_relu, kernel_regularizer=reg(), bias_regularizer=reg())\n",
    "x = tf.layers.dropout(x, rate=0.5, training=training)\n",
    "    \n",
    "x = tf.layers.conv2d(x, 96, (1, 1), activation=leaky_relu, kernel_regularizer=reg(), bias_regularizer=reg())\n",
    "x = tf.layers.dropout(x, rate=0.4, training=training)\n",
    "    \n",
    "logits = tf.layers.conv2d(x, 3, (1, 1), bias_regularizer=reg(l2=0.01))\n",
    "prob = tf.nn.sigmoid(logits, name='prob')\n",
    "\n",
    "\n",
    "reward, reward_pred = single_class_split(label, prob[:, 0, 0])\n",
    "_, logits_pred = single_class_split(label, logits[:, 0, 0])\n",
    "\n",
    "weights = tf.abs(0.6 - reward) # 1.0 or tf.abs(0.75 - reward) or label[:, 2]\n",
    "loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=reward, logits=logits_pred, weights=weights)\n",
    "loss_reg = loss + tf.add_n(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "    \n",
    "accuracy = tf_accuracy(reward, reward_pred)\n",
    "precision = tf_precision(reward, reward_pred)\n",
    "recall = tf_recall(reward, reward_pred)\n",
    "f1 = tf_f1(precision, recall, beta=0.5)\n",
    "\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)  # For batch normalization layers\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=2e-5).minimize(loss_reg, name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/berscheid/Documents/data/cylinder-1/models/model-specific-3\n",
      "Epoch\tTime[s]\tTrain Accuracy\tTest Loss\tAccuracy\tPrecision\tRecall\t\tF1\n",
      "   -1\t0.00\t-1.0000\t\t0.1141\t\t0.9068\t\t0.9047\t\t0.7794\t\t0.8765\n",
      "    0\t17.47\t0.9087\t\t0.1141\t\t0.9056\t\t0.9064\t\t0.7754\t\t0.8768\n",
      "    1\t30.78\t0.9132\t\t0.1146\t\t0.9077\t\t0.9038\t\t0.7800\t\t0.8760\n",
      "    2\t43.44\t0.9096\t\t0.1143\t\t0.9040\t\t0.9047\t\t0.7765\t\t0.8758\n",
      "    3\t55.84\t0.9159\t\t0.1143\t\t0.9073\t\t0.9030\t\t0.7792\t\t0.8752\n",
      "    4\t68.28\t0.9177\t\t0.1142\t\t0.9058\t\t0.9016\t\t0.7804\t\t0.8744\n",
      "    5\t80.50\t0.9186\t\t0.1138\t\t0.9085\t\t0.8996\t\t0.7838\t\t0.8737\n",
      "Model saved in file: /home/berscheid/Documents/data/cylinder-1/models/model-specific-3\n",
      "    6\t93.07\t0.9096\t\t0.1160\t\t0.9039\t\t0.8985\t\t0.7837\t\t0.8730\n",
      "    7\t105.38\t0.9213\t\t0.1135\t\t0.9063\t\t0.8995\t\t0.7827\t\t0.8734\n",
      "Model saved in file: /home/berscheid/Documents/data/cylinder-1/models/model-specific-3\n",
      "    8\t118.29\t0.9195\t\t0.1120\t\t0.9075\t\t0.9002\t\t0.7824\t\t0.8739\n",
      "Model saved in file: /home/berscheid/Documents/data/cylinder-1/models/model-specific-3\n",
      "    9\t131.40\t0.9304\t\t0.1166\t\t0.9076\t\t0.8974\t\t0.7858\t\t0.8726\n",
      "   10\t144.17\t0.9213\t\t0.1156\t\t0.9039\t\t0.8972\t\t0.7853\t\t0.8724\n",
      "   11\t156.92\t0.9241\t\t0.1159\t\t0.9063\t\t0.8968\t\t0.7858\t\t0.8722\n",
      "   12\t169.61\t0.9231\t\t0.1144\t\t0.9043\t\t0.8981\t\t0.7839\t\t0.8726\n",
      "   13\t181.85\t0.9241\t\t0.1179\t\t0.9003\t\t0.8990\t\t0.7814\t\t0.8728\n",
      "   14\t194.24\t0.9168\t\t0.1160\t\t0.9084\t\t0.8977\t\t0.7834\t\t0.8723\n",
      "   15\t206.24\t0.9213\t\t0.1136\t\t0.9054\t\t0.8987\t\t0.7823\t\t0.8727\n",
      "   16\t218.24\t0.9159\t\t0.1138\t\t0.9049\t\t0.8992\t\t0.7816\t\t0.8729\n",
      "   17\t230.35\t0.9195\t\t0.1136\t\t0.9063\t\t0.8999\t\t0.7808\t\t0.8733\n",
      "   18\t242.30\t0.9087\t\t0.1167\t\t0.9041\t\t0.8995\t\t0.7810\t\t0.8730\n",
      "   19\t254.24\t0.9150\t\t0.1144\t\t0.9044\t\t0.8995\t\t0.7807\t\t0.8730\n",
      "   20\t266.63\t0.9241\t\t0.1173\t\t0.8977\t\t0.9005\t\t0.7783\t\t0.8731\n",
      "   21\t279.18\t0.9222\t\t0.1141\t\t0.9074\t\t0.9003\t\t0.7788\t\t0.8731\n",
      "   22\t291.72\t0.9358\t\t0.1151\t\t0.9031\t\t0.9007\t\t0.7781\t\t0.8732\n",
      "   23\t303.90\t0.9231\t\t0.1162\t\t0.9034\t\t0.9009\t\t0.7776\t\t0.8732\n",
      "   24\t316.10\t0.9231\t\t0.1147\t\t0.9043\t\t0.9009\t\t0.7774\t\t0.8732\n",
      "   25\t328.25\t0.9286\t\t0.1164\t\t0.9050\t\t0.9005\t\t0.7778\t\t0.8730\n",
      "   26\t340.67\t0.9331\t\t0.1159\t\t0.9071\t\t0.8998\t\t0.7789\t\t0.8727\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f2e3345efe09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mexport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;32m~/Documents/bin_picking/jupyter/tensorflow_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_iterator, train_batches_per_epoch, test_iterator, epochs, early_stopping_patience, load, save, export)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m#            for batch in tqdm(range(train_batches_per_epoch), unit='batches', leave=False, dynamic_ncols=True):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_metrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'handle:0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'training:0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monEpochEnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_patience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow_model import Model\n",
    "\n",
    "model = Model(\n",
    "    test_metrices=[loss, accuracy, precision, recall, f1, reward_pred],\n",
    "    inputs={'image': image, 'ann': ann},\n",
    "    outputs={'prob': prob},\n",
    "    model_input_path=generator.model_directory + 'model-specific-3',\n",
    "    model_output_path=generator.model_directory + 'model-specific-3'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_iterator, train_loader.batches_per_epoch, test_iterator,\n",
    "    epochs=500,\n",
    "    early_stopping_patience=100,\n",
    "    load=True,\n",
    "    save=True,\n",
    "    export=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
