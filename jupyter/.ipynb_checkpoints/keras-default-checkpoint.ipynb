{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio: 0.18\n",
      "Progress: 1000 of 19889\n",
      "Progress: 2000 of 19889\n",
      "Progress: 3000 of 19889\n",
      "Progress: 4000 of 19889\n",
      "Progress: 5000 of 19889\n",
      "Progress: 6000 of 19889\n",
      "Progress: 7000 of 19889\n",
      "Progress: 8000 of 19889\n",
      "Progress: 9000 of 19889\n",
      "Progress: 10000 of 19889\n",
      "Progress: 11000 of 19889\n",
      "Progress: 12000 of 19889\n",
      "Progress: 13000 of 19889\n",
      "Progress: 14000 of 19889\n",
      "Progress: 15000 of 19889\n",
      "Progress: 16000 of 19889\n",
      "Progress: 17000 of 19889\n",
      "Progress: 18000 of 19889\n",
      "Progress: 19000 of 19889\n",
      "Written training data to /home/berscheid/Documents/data/cube-1/gen-default/train.csv\n",
      "Written test data to /home/berscheid/Documents/data/cube-1/gen-default/test.csv\n"
     ]
    }
   ],
   "source": [
    "from generate_input_planar_pose import GenerateInputPlanarPose\n",
    "\n",
    "directory = os.path.expanduser('~/Documents/data/')\n",
    "\n",
    "generator = GenerateInputPlanarPose([\n",
    "    directory + 'cube-1/cube-1.db',\n",
    "    directory + 'cylinder-1/cylinder-1a.db',\n",
    "    directory + 'cylinder-1/cylinder-1b.db',\n",
    "], output_folder='gen-default/')\n",
    "\n",
    "generator.generateInput({\n",
    "    'did_grasp_weight': 0.13,\n",
    "    'flip_augmentation': True,\n",
    "    'flip_modes': [0, 1, -1],\n",
    "    'force_rewrite': False,\n",
    "    'height_augmentation': False,\n",
    "    'size_cropped': (200, 200),\n",
    "    'size_input': (752, 480),\n",
    "    'size_output': (32, 32),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 63472, Test: 4021\n",
      "Train Mean Reward: 0.181, Test: 0.177\n"
     ]
    }
   ],
   "source": [
    "from keras_utils import load_data\n",
    "\n",
    "train_images, train_labels = load_data(generator.train_output_filename)\n",
    "test_images, test_labels = load_data(generator.test_output_filename)\n",
    "\n",
    "print('Train: {}, Test: {}'.format(len(train_labels), len(test_labels)))\n",
    "print('Train Mean Reward: {:0.3f}, Test: {:0.3f}'.format(train_labels[:, 0].mean(), test_labels[:, 0].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63472 samples, validate on 4021 samples\n",
      "Epoch 1/600\n",
      "63472/63472 [==============================] - 5s 86us/step - loss: 3.9748 - crossentropy: 0.8010 - accuracy: 0.5208 - precision: 0.1951 - val_loss: 3.8013 - val_crossentropy: 0.6323 - val_accuracy: 0.7670 - val_precision: 0.2946\n",
      "\n",
      "Epoch 00001: val_crossentropy improved from inf to 0.63228, saving model to /home/berscheid/Documents/data/cube-1/models/model-2test.h5\n",
      "Epoch 2/600\n",
      "63472/63472 [==============================] - 4s 70us/step - loss: 3.9220 - crossentropy: 0.7578 - accuracy: 0.5469 - precision: 0.2010 - val_loss: 3.7688 - val_crossentropy: 0.6094 - val_accuracy: 0.7446 - val_precision: 0.3167\n",
      "\n",
      "Epoch 00002: val_crossentropy improved from 0.63228 to 0.60944, saving model to /home/berscheid/Documents/data/cube-1/models/model-2test.h5\n",
      "Epoch 3/600\n",
      " 7808/63472 [==>...........................] - ETA: 3s - loss: 3.8893 - crossentropy: 0.7305 - accuracy: 0.5694 - precision: 0.2152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-198bdde4b88f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcheckpointer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_learning_rate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras_utils import crossentropy, accuracy, precision\n",
    "\n",
    "load_model = False\n",
    "train_model = True\n",
    "export_model = False\n",
    "load_model_path = generator.model_directory + 'model-2test'\n",
    "save_model_path = generator.model_directory + 'model-2test'\n",
    "export_model_path = save_model_path + '-sm'\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "image = k.Input(shape=(None, None, 1), name='image')\n",
    "\n",
    "reg = k.regularizers.l1_l2(l1=0.0, l2=0.01)\n",
    "\n",
    "x = k.layers.Conv2D(32, kernel_size=(5, 5), strides=(2, 2), kernel_regularizer=reg, bias_regularizer=reg)(image)\n",
    "x = k.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = k.layers.BatchNormalization()(x)\n",
    "x = k.layers.Dropout(rate=0.4)(x)\n",
    "# x = tf.layers.dropout(x, rate=0.4, training=apply_dropout, name='Asdf')\n",
    "\n",
    "x = k.layers.Conv2D(48, kernel_size=(5, 5), kernel_regularizer=reg, bias_regularizer=reg)(x)\n",
    "x = k.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = k.layers.BatchNormalization()(x)\n",
    "x = k.layers.Dropout(rate=0.4)(x)\n",
    "\n",
    "x = k.layers.Conv2D(64, kernel_size=(5, 5), kernel_regularizer=reg, bias_regularizer=reg)(x)\n",
    "x = k.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = k.layers.BatchNormalization()(x)\n",
    "x = k.layers.Dropout(rate=0.4)(x)\n",
    "\n",
    "x = k.layers.Conv2D(142, kernel_size=(6, 6), kernel_regularizer=reg, bias_regularizer=reg)(x)\n",
    "x = k.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = k.layers.Dropout(rate=0.4)(x)\n",
    "\n",
    "x = k.layers.Conv2D(128, kernel_size=(1, 1), kernel_regularizer=reg, bias_regularizer=reg)(x)\n",
    "x = k.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = k.layers.Dropout(rate=0.2)(x)\n",
    "\n",
    "prob = k.layers.Conv2D(3, kernel_size=(1, 1), activation='sigmoid', name='prob')(x)\n",
    "prob_training = k.layers.Reshape((3,))(prob)\n",
    "\n",
    "\n",
    "model = k.Model(inputs=image, outputs=prob_training)\n",
    "\n",
    "if load_model:\n",
    "    model.load_weights(load_model_path + '.h5')\n",
    "\n",
    "    \n",
    "optimizer = k.optimizers.Adam(lr=1e-6)\n",
    "model.compile(optimizer=optimizer, loss=crossentropy, metrics=[crossentropy, accuracy, precision])\n",
    "\n",
    "\n",
    "if train_model:\n",
    "    checkpointer = k.callbacks.ModelCheckpoint(save_model_path + '.h5', monitor='val_crossentropy', verbose=1, save_best_only=True)\n",
    "    early_stopping = k.callbacks.EarlyStopping(monitor='val_crossentropy', patience=120)\n",
    "    reduce_learning_rate = k.callbacks.ReduceLROnPlateau(factor=0.2, verbose=1, patience=30)\n",
    "    \n",
    "    if load_model:\n",
    "        evaluation = model.evaluate(test_images, test_labels)\n",
    "        print(model.metrics_names, evaluation)\n",
    "        checkpointer.best = evaluation[model.metrics_names.index('crossentropy')]\n",
    "\n",
    "    history = model.fit(train_images, train_labels, batch_size=128, epochs=600, shuffle=True, validation_data=(test_images, test_labels), callbacks=[checkpointer, early_stopping, reduce_learning_rate])\n",
    "else:\n",
    "    evaluation = model.evaluate(test_images, test_labels)\n",
    "    print(model.metrics_names, evaluation)\n",
    "\n",
    "    \n",
    "if load_model and export_model:\n",
    "    tf.saved_model.simple_save(K.get_session(), export_model_path, inputs={'image': image}, outputs={'prob': prob})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [print(n.name) for n in tf.get_default_graph().as_graph_def().node];\n",
    "# tf.keras.backend.get_session().graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50010496 0.50226635 0.502743  ]\n",
      " [0.4997311  0.5009124  0.5054303 ]\n",
      " [0.49922705 0.50172144 0.5047281 ]\n",
      " ...\n",
      " [0.49974835 0.50052446 0.50227803]\n",
      " [0.49826512 0.49930432 0.5049339 ]\n",
      " [0.4999553  0.5005387  0.5031104 ]]\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = k.models.load_model(save_model_path + '.h5', compile=False)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    # monte_carlo_predict([test_images, 1])\n",
    "    # a = sess.run(newLayer, feed_dict={model.input: test_images})\n",
    "    # print(a)\n",
    "    a = sess.run(model.output, feed_dict={model.input: test_images})\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
