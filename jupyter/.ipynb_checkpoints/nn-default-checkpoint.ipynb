{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Mean: 0.206\n",
      "Progress: 1000 of 24088\n",
      "Progress: 2000 of 24088\n",
      "Progress: 3000 of 24088\n",
      "Progress: 4000 of 24088\n",
      "Progress: 5000 of 24088\n",
      "Progress: 6000 of 24088\n",
      "Progress: 7000 of 24088\n",
      "Progress: 8000 of 24088\n",
      "Progress: 9000 of 24088\n",
      "Progress: 10000 of 24088\n",
      "Progress: 11000 of 24088\n",
      "Progress: 12000 of 24088\n",
      "Progress: 13000 of 24088\n",
      "Progress: 14000 of 24088\n",
      "Progress: 15000 of 24088\n",
      "Progress: 16000 of 24088\n",
      "Progress: 17000 of 24088\n",
      "Progress: 18000 of 24088\n",
      "Progress: 19000 of 24088\n",
      "Progress: 20000 of 24088\n",
      "Progress: 21000 of 24088\n",
      "Progress: 22000 of 24088\n",
      "Progress: 23000 of 24088\n",
      "Progress: 24000 of 24088\n",
      "Written training data to /home/berscheid/Documents/data/cylinder-cube-1/gen-inpaint/train.csv\n",
      "Written test data to /home/berscheid/Documents/data/cylinder-cube-1/gen-inpaint/test.csv\n"
     ]
    }
   ],
   "source": [
    "from generate_input_planar_pose import GenerateInputPlanarPose\n",
    "\n",
    "directory = os.path.expanduser('~/Documents/data/')\n",
    "\n",
    "generator = GenerateInputPlanarPose([\n",
    "    directory + 'cylinder-cube-1/cylinder-cube-1.db',\n",
    "    directory + 'cylinder-1/cylinder-1b.db',\n",
    "    directory + 'cube-1/cube-1.db',\n",
    "    directory + 'cylinder-1/cylinder-1a.db',\n",
    "], test_files=[\n",
    "#    directory + 'all-1/all-1.db',\n",
    "], output_folder='gen-inpaint/')\n",
    "\n",
    "generator.generateInput({\n",
    "    'did_grasp_weight': 0.13,\n",
    "    'force_rewrite': False,\n",
    "    'inpaint': True,\n",
    "    'size_cropped': (200, 200),\n",
    "    'size_input': (752, 480),\n",
    "    'size_output': (32, 32),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 4868\n",
      "Reward Mean: 0.2029580936729663\n",
      "Length: 19220\n",
      "Reward Mean: 0.20665972944849115\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_loader import DataLoader\n",
    "\n",
    "test_loader = DataLoader(generator.test_output_filename)\n",
    "train_loader = DataLoader(generator.train_output_filename, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_utils import get_augmentation, single_class_split, tf_accuracy, tf_precision, tf_recall, tf_f1\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# tf.set_random_seed(3)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(train_loader.nextBatch, (tf.float32, tf.float32), ((None, None, None, 1), (None, 3)))\n",
    "train_dataset = train_dataset.map(get_augmentation(flip_up_down=False, flip_left_right=False, height=False, noise=False, defects=False, blur=False), num_parallel_calls=4)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(test_loader.entireBatch, (tf.float32, tf.float32))\n",
    "\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=(), name='handle')\n",
    "iterator = tf.data.Iterator.from_string_handle(handle, train_dataset.output_types, train_dataset.output_shapes)\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "    \n",
    "image, label = iterator.get_next()\n",
    "\n",
    "\n",
    "def act(x): return tf.nn.leaky_relu(x, 0.1)\n",
    "def reg(l1=0.0, l2=0.3): return tf.contrib.layers.l1_l2_regularizer(l1, l2)\n",
    "    \n",
    "    \n",
    "training = tf.placeholder_with_default(False, (), name='training')\n",
    "apply_dropout = tf.placeholder_with_default(training, (), name='apply_dropout')\n",
    "image = tf.identity(image, name='image')\n",
    "label = tf.identity(label, name='label')\n",
    "\n",
    "\n",
    "# Second layer with uncertainty about depth\n",
    "#h = tf.to_float(tf.equal(image, 0.0))\n",
    "#x = tf.concat([h, image], axis=3)\n",
    "    \n",
    "x = tf.layers.conv2d(image, 32, (5, 5), strides=(2, 2), activation=act, kernel_regularizer=reg(), bias_regularizer=reg())\n",
    "x = tf.layers.batch_normalization(x, training=training)\n",
    "#x = tf.layers.dropout(x, 0.4, training=apply_dropout)\n",
    "    \n",
    "x = tf.layers.conv2d(x, 48, (5, 5), strides=(1, 1), dilation_rate=(1, 1), activation=act, kernel_regularizer=reg(), bias_regularizer=reg())\n",
    "x = tf.layers.batch_normalization(x, training=training)\n",
    "#x = tf.layers.dropout(x, 0.4, training=apply_dropout)\n",
    "\n",
    "x = tf.layers.conv2d(x, 64, (5, 5), dilation_rate=(1, 1), activation=act, kernel_regularizer=reg(), bias_regularizer=reg())\n",
    "x = tf.layers.batch_normalization(x, training=training)\n",
    "x = tf.layers.dropout(x, 0.4, training=apply_dropout)\n",
    "\n",
    "x = tf.layers.conv2d(x, 142, (6, 6), dilation_rate=(1, 1), activation=act, kernel_regularizer=reg(), bias_regularizer=reg())\n",
    "# x = tf.layers.batch_normalization(x, training=training)\n",
    "x = tf.layers.dropout(x, 0.3, training=apply_dropout)\n",
    "    \n",
    "x = tf.layers.conv2d(x, 128, (1, 1), dilation_rate=(1, 1), activation=act, kernel_regularizer=reg(), bias_regularizer=reg())\n",
    "x = tf.layers.dropout(x, 0.3, training=apply_dropout)\n",
    "    \n",
    "logits = tf.layers.conv2d(x, 3, (1, 1), dilation_rate=(1, 1), bias_regularizer=reg(l2=0.1))\n",
    "prob = tf.nn.sigmoid(logits, name='prob')\n",
    "# var_prob = tf.expand_dims(tf.abs(tf.reduce_mean(tf.reduce_mean(tf.gradients(prob, [x_depth])[0], axis=2, keepdims=True), axis=1, keepdims=True)), 3, name='var_prob')\n",
    "\n",
    "    \n",
    "reward, reward_pred = single_class_split(label, prob[:, 0, 0])\n",
    "_, logits_pred = single_class_split(label, logits[:, 0, 0])\n",
    "\n",
    "weights = tf.abs(0.6 - reward) # 1.0 or tf.abs(0.75 - reward) or label[:, 2]\n",
    "loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=reward, logits=logits_pred, weights=weights)\n",
    "loss_reg = loss + tf.add_n(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "    \n",
    "accuracy = tf_accuracy(reward, reward_pred)\n",
    "precision = tf_precision(reward, reward_pred)\n",
    "recall = tf_recall(reward, reward_pred)\n",
    "f1 = tf_f1(precision, recall, beta=0.5)\n",
    "\n",
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)  # For batch normalization layers\n",
    "with tf.control_dependencies(extra_update_ops):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=1e-5).minimize(loss_reg, name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/berscheid/Documents/data/cylinder-cube-1/models/model-4-inpaint\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/berscheid/Documents/data/cylinder-cube-1/models/model-4-inpaint-sm/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_model import Model\n",
    "\n",
    "model = Model(\n",
    "    test_metrices=[loss, accuracy, precision, recall, f1],\n",
    "    inputs={'image': image, 'apply_dropout': apply_dropout},\n",
    "    outputs={'prob': prob},\n",
    "    model_input_path=generator.model_directory + 'model-4-inpaint',\n",
    "    model_output_path=generator.model_directory + 'model-4-inpaint'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_iterator, train_loader.batches_per_epoch, test_iterator,\n",
    "    epochs=1500,\n",
    "    early_stopping_patience=500,\n",
    "    load=True,\n",
    "    save=True,\n",
    "    export=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-17ab8bc25f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model = Model(\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtest_metrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mmodel_input_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model-4-2lyr'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow_model import Model\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = Model(\n",
    "    test_metrices=[loss, accuracy, precision, recall, f1],\n",
    "    model_input_path=generator.model_directory + 'model-4-2lyr'\n",
    ")\n",
    "\n",
    "train_handle = model.sess.run(train_iterator.string_handle())\n",
    "model.sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "model.load()\n",
    "model.sess.run(train_iterator.initializer)\n",
    "\n",
    "\n",
    "batch_images = model.sess.run(image, feed_dict={handle: train_handle, training: True})\n",
    "image_data = np.squeeze(batch_images[0], axis=2)\n",
    "\n",
    "print(image_data.min(), image_data.max())\n",
    "plt.imshow(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.hist(prob_calc.flatten(), bins=np.arange(0, 1, 0.01))\n",
    "plt.hist(test_labels[:, 0], bins=[0, 0.01, 0.99, 1], alpha=0.5)\n",
    "plt.title('Histogram of the Grasp Reward Prediction of the Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largestErrorsIn(probs, ids, labels):\n",
    "    # print(probs[np.arange(len(probs))\n",
    "    diff = np.abs(probs - labels[:len(probs), 0])\n",
    "    # diff = np.abs(probs[np.arange(len(probs)), labels[:, 1].astype(int)] - labels[:, 0])\n",
    "    print('Mean diff: ', diff.mean())\n",
    "\n",
    "    idxs = diff.argsort()[-200:][::-1]\n",
    "\n",
    "    for idx in idxs:\n",
    "        print()\n",
    "        print('ID: ', ids[idx])\n",
    "        print('Diff: ', diff[idx])\n",
    "        print(probs[idx])\n",
    "        print(labels[idx])\n",
    "        \n",
    "# largestErrorsIn(prob_calc, test_id, test_labels)\n",
    "largestErrorsIn(np.array(train_predict), train_id, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 20):\n",
    "    print()\n",
    "    print(test_id[-i])\n",
    "    print(prob_calc[-i])\n",
    "    print(test_labels[-i])\n",
    "    img = mpimg.imread(test_image_names[-i])\n",
    "    plt.figure()\n",
    "    plt.title(test_id[-i])\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
